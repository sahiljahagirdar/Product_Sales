This document Stored all the Preprocessing steps that I performed on the project:

1. Imported Product_sales.csv file
    * Performed basic check's
        - head()
        - tail()
        - descibe
        - info
2. Checked null values 
    * Columns having null values:
        - Product_ID
        - Source
        - Mobile
        - Sales_Agent
        - Location
3. Five columns having null values
4. Checked and fixed duplicate values 
5. Performed EDA to get business insights
    * Business insights:
        -
        -
        -
        -
        -
6. Started with feature Engineering
    Steps performed in feature Engineering:
        1. Dropped Unneccessary Columns:
            - Mobile, Email [NOT HELPFUL FOR PREDICTION]
        2. Fixed null values:
            - My null values were categorical, Replaced null values with MODE 
        3. Fixed Created column 
            - Date and time was in single column fixed it with keep seperate columns (MONTH,DAY_OF_WEEK,HOUR,IS_WEEKEND)
        4. Change Datatype of Product_ID column (float --> int)
        5. Fixed Source column 
            - There were many categorical data, Reduced categorical data
            - Category with [ Website, US Website, Just Dial ] --> Website
            - Category starting with [ Live Chat ] --> Live Chat
            - Category with [ Call, Personal Contact ] --> Call_Personal
            - Category with [ E-Mail Message, E-mail Campaign, CRM form, SMS Campaign ] --> Email_Campaign
            - Category with [ By Recommendation, Customer Referral, Existing Client, Existing Customer ] --> Referral_Existing
            - Else --> Other
            { With this Reduced 29 categories into 6 }
        6. Fixed Status column
            - Status column containing many categorical data, Reduced it to High_Potential,Low_Potential
            - categories present:
                - Junk Lead
                - Not Responding
                - CONVERTED
                - Just Enquiry
                - Potential
                - Long Term
                - In Progress Positive
                - In Progress Negative
                - LOST
                - Open
                - converted
            * High_Potential
                - Just Enquiry, Potential, Long Term, In Progress Positive, Open, CONVERTED, converted
            * Low_Potential
                - Junk Lead, Not Responding, In Progress Negative, LOST
        7. Fixed Location Columns
            - Location Column having many categorical data, Reduced it to Major cities, International, Other
            - categories present:
                - Other Locations
                - Bangalore
                - Chennai
                - Hyderabad
                - Delhi
                - Mumbai
                - Pune
                - UAE
                - Trivandrum
                - Kolkata
                - USA
                - UK 
                - Singapore
                - Malaysia
                - EUROPE
                - Howrah
            * Major cities
                - Bangalore, Chennai, Hyderabad, Delhi, Mumbai, Pune, Trivandrum, Kolkata
            * International
                - UAE, USA, UK, AUSTRALIA, Singapore, Malaysia, EUROPE
            * Other
7. Encoding categorical Columns
    Encoded my target column
        - High Potential --> 1
        - Low Potential --> 0
    Created 2 datasets Label_df and ohe_df 
        Label_df
            - Label_df will be used for Tree based models
            - The dataset contains columns encoded using Label Encoding
            - Columns required encoding ['Sales_Agent', 'Delivery_Mode', 'Source_grouped', 'Location_grouped']
        ohe_df
            - ohe_df dataset will be used for Linear models 
            - The dataset contains columns encoded using ONE HOT ENCODING 
            - columns required encoding ['Sales_Agent', 'Delivery_Mode', 'Source_grouped', 'Location_grouped']
8. seperate target column
    There are 2 datasets Label_df and ohe_df
        - Label_df
            - xl --> Data except target column
            - yl --> Target column
        - ohe_df
            - x0 --> Data except target column
            - y0 --> Target column
9. Applied Standard Scaling
    Applied Standard Scaling on ohe_df (Tree based model don't require Scaling)
        - columns applied scaling ['Product_ID', 'Month', 'DayOfWeek', 'Hour']
10. Performed Train test split
    performed train test split on both dataset Label_df and ohe_df
        Label_df
            - x_trainl, x_testl, y_trainl, y_testl
            - 80% for training and 20% for testing
        ohe_df
            - x_train0, x_test0, y_train0, y_test0
            - 80% for training and 20% for testing
11. Applied SMOTE on ohe_df
    performed SMOTE balancing
        ohe_df
            - x_train0_sm,y_train0_sm
12. Trained Logistic Regression model
    Used OHE encoding model for training [x0,y0]
    Tested datasets
        - Tested the model accuracy using original dataset
        - Tested on SMOTE dataset 
        - Tested with class weight Balance
        - Performed Hyper parameter tuning
13. Trained KNN model 
    Used OHE encoding model for training [x0,y0]
        - Tested using using original dataset
        - Tested on SMOTE dataset
        - Performed Hyper parameter tuning
14. Trained SVM model
    Used OHE encoding model for training [x0,y0]
        - Tested using original dataset 
        - Tested on SMOTE dataset
        - 

